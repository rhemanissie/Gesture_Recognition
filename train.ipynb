{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FHTXnoUFN7eZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FoDohkhfal_5"
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t5zkBfD2a7DF"
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "go6Lxiuga-3M"
   },
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I_A3hv_SbBZc"
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    # face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFDEyhd2bm14"
   },
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Point_Dataset_5') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['forward', 'backward', 'pause-play','full-screen','normal-screen'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "1GjKmhtOcNOK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NyMWBwPcVvW",
    "outputId": "9c6fcc6c-25ef-469b-cd68-b64eb5411343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('forward'): 0,\n",
       " np.str_('backward'): 1,\n",
       " np.str_('pause-play'): 2,\n",
       " np.str_('full-screen'): 3,\n",
       " np.str_('normal-screen'): 4}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xxc_QmgScdJb",
    "outputId": "952e9111-4c51-400b-d88f-ca2bcc50868d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 0\n",
      "forward 1\n",
      "forward 2\n",
      "forward 3\n",
      "forward 4\n",
      "forward 5\n",
      "forward 6\n",
      "forward 7\n",
      "forward 8\n",
      "forward 9\n",
      "forward 10\n",
      "forward 11\n",
      "forward 12\n",
      "forward 13\n",
      "forward 14\n",
      "forward 15\n",
      "forward 16\n",
      "forward 17\n",
      "forward 18\n",
      "forward 19\n",
      "forward 20\n",
      "forward 21\n",
      "forward 22\n",
      "forward 23\n",
      "forward 24\n",
      "forward 25\n",
      "forward 26\n",
      "forward 27\n",
      "forward 28\n",
      "forward 29\n",
      "backward 0\n",
      "backward 1\n",
      "backward 2\n",
      "backward 3\n",
      "backward 4\n",
      "backward 5\n",
      "backward 6\n",
      "backward 7\n",
      "backward 8\n",
      "backward 9\n",
      "backward 10\n",
      "backward 11\n",
      "backward 12\n",
      "backward 13\n",
      "backward 14\n",
      "backward 15\n",
      "backward 16\n",
      "backward 17\n",
      "backward 18\n",
      "backward 19\n",
      "backward 20\n",
      "backward 21\n",
      "backward 22\n",
      "backward 23\n",
      "backward 24\n",
      "backward 25\n",
      "backward 26\n",
      "backward 27\n",
      "backward 28\n",
      "backward 29\n",
      "pause-play 0\n",
      "pause-play 1\n",
      "pause-play 2\n",
      "pause-play 3\n",
      "pause-play 4\n",
      "pause-play 5\n",
      "pause-play 6\n",
      "pause-play 7\n",
      "pause-play 8\n",
      "pause-play 9\n",
      "pause-play 10\n",
      "pause-play 11\n",
      "pause-play 12\n",
      "pause-play 13\n",
      "pause-play 14\n",
      "pause-play 15\n",
      "pause-play 16\n",
      "pause-play 17\n",
      "pause-play 18\n",
      "pause-play 19\n",
      "pause-play 20\n",
      "pause-play 21\n",
      "pause-play 22\n",
      "pause-play 23\n",
      "pause-play 24\n",
      "pause-play 25\n",
      "pause-play 26\n",
      "pause-play 27\n",
      "pause-play 28\n",
      "pause-play 29\n",
      "full-screen 0\n",
      "full-screen 1\n",
      "full-screen 2\n",
      "full-screen 3\n",
      "full-screen 4\n",
      "full-screen 5\n",
      "full-screen 6\n",
      "full-screen 7\n",
      "full-screen 8\n",
      "full-screen 9\n",
      "full-screen 10\n",
      "full-screen 11\n",
      "full-screen 12\n",
      "full-screen 13\n",
      "full-screen 14\n",
      "full-screen 15\n",
      "full-screen 16\n",
      "full-screen 17\n",
      "full-screen 18\n",
      "full-screen 19\n",
      "full-screen 20\n",
      "full-screen 21\n",
      "full-screen 22\n",
      "full-screen 23\n",
      "full-screen 24\n",
      "full-screen 25\n",
      "full-screen 26\n",
      "full-screen 27\n",
      "full-screen 28\n",
      "full-screen 29\n",
      "normal-screen 0\n",
      "normal-screen 1\n",
      "normal-screen 2\n",
      "normal-screen 3\n",
      "normal-screen 4\n",
      "normal-screen 5\n",
      "normal-screen 6\n",
      "normal-screen 7\n",
      "normal-screen 8\n",
      "normal-screen 9\n",
      "normal-screen 10\n",
      "normal-screen 11\n",
      "normal-screen 12\n",
      "normal-screen 13\n",
      "normal-screen 14\n",
      "normal-screen 15\n",
      "normal-screen 16\n",
      "normal-screen 17\n",
      "normal-screen 18\n",
      "normal-screen 19\n",
      "normal-screen 20\n",
      "normal-screen 21\n",
      "normal-screen 22\n",
      "normal-screen 23\n",
      "normal-screen 24\n",
      "normal-screen 25\n",
      "normal-screen 26\n",
      "normal-screen 27\n",
      "normal-screen 28\n",
      "normal-screen 29\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        print(action,sequence)\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCFnMJKZciBt",
    "outputId": "5a851748-080a-46fe-e8f0-e843660e9a4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 30, 258)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xo891Uiznz2M",
    "outputId": "6b97f4c7-a01c-42f3-ca7f-5f83fcdb739a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYiO0VMFn1wO",
    "outputId": "c50259e4-6438-4379-a9dd-85e54adaf5d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "62QHHmUtn-M9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "V8VOizStoJAv"
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNaletT_oQrU"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(30,258)))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tpl_zEDkoS8G",
    "outputId": "fd42bf2b-e4f3-4b40-817f-561b1e23f123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "pP3tOeJ3oWXK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=5,            # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfcOAn9UolGb",
    "outputId": "5c023754-aedc-43c6-fec7-4d80a5917552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - categorical_accuracy: 0.1726 - loss: 1.6735\n",
      "Epoch 2/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.3068 - loss: 1.5359\n",
      "Epoch 3/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.4150 - loss: 1.4452\n",
      "Epoch 4/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.4221 - loss: 1.3621\n",
      "Epoch 5/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.5756 - loss: 1.1871\n",
      "Epoch 6/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.6725 - loss: 1.0232\n",
      "Epoch 7/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.7701 - loss: 0.8949\n",
      "Epoch 8/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.6728 - loss: 0.9554\n",
      "Epoch 9/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.7231 - loss: 1.0141\n",
      "Epoch 10/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.7065 - loss: 0.7196\n",
      "Epoch 11/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - categorical_accuracy: 0.7676 - loss: 0.6100\n",
      "Epoch 12/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.6967 - loss: 0.7603\n",
      "Epoch 13/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.8177 - loss: 0.6359\n",
      "Epoch 14/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.7555 - loss: 0.5129\n",
      "Epoch 15/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.8674 - loss: 0.3447\n",
      "Epoch 16/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - categorical_accuracy: 0.7536 - loss: 0.5835\n",
      "Epoch 17/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.8238 - loss: 0.5743\n",
      "Epoch 18/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.7493 - loss: 0.5985\n",
      "Epoch 19/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.7737 - loss: 0.4962\n",
      "Epoch 20/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.8360 - loss: 0.4599\n",
      "Epoch 21/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.8633 - loss: 0.3663\n",
      "Epoch 22/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.8980 - loss: 0.2715\n",
      "Epoch 23/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9195 - loss: 0.2525\n",
      "Epoch 24/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.8853 - loss: 0.2647\n",
      "Epoch 25/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.7937 - loss: 0.6128\n",
      "Epoch 26/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.8251 - loss: 0.4321\n",
      "Epoch 27/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.8931 - loss: 0.4255\n",
      "Epoch 28/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.8901 - loss: 0.3920\n",
      "Epoch 29/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.8694 - loss: 0.3759\n",
      "Epoch 30/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9013 - loss: 0.2782\n",
      "Epoch 31/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9653 - loss: 0.2137\n",
      "Epoch 32/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9380 - loss: 0.1984\n",
      "Epoch 33/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9346 - loss: 0.2151\n",
      "Epoch 34/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9229 - loss: 0.2034\n",
      "Epoch 35/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.9705 - loss: 0.1631\n",
      "Epoch 36/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9432 - loss: 0.1262\n",
      "Epoch 37/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9631 - loss: 0.1130\n",
      "Epoch 38/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.9197 - loss: 0.1827\n",
      "Epoch 39/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9448 - loss: 0.1362\n",
      "Epoch 40/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9726 - loss: 0.1150\n",
      "Epoch 41/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9687 - loss: 0.0861\n",
      "Epoch 42/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9602 - loss: 0.0880\n",
      "Epoch 43/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9920 - loss: 0.0287\n",
      "Epoch 44/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.9870 - loss: 0.1592\n",
      "Epoch 45/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9124 - loss: 0.2965\n",
      "Epoch 46/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.8663 - loss: 0.5369\n",
      "Epoch 47/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.8457 - loss: 0.4046\n",
      "Epoch 48/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.7881 - loss: 0.4023\n",
      "Epoch 49/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9343 - loss: 0.2397\n",
      "Epoch 50/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9832 - loss: 0.1680\n",
      "Epoch 51/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.9795 - loss: 0.1411\n",
      "Epoch 52/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9734 - loss: 0.1328\n",
      "Epoch 53/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.9892 - loss: 0.0947\n",
      "Epoch 54/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.9946 - loss: 0.0505\n",
      "Epoch 55/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.9946 - loss: 0.0341\n",
      "Epoch 56/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.9977 - loss: 0.0192\n",
      "Epoch 57/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 1.0000 - loss: 0.0254\n",
      "Epoch 58/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 59/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 60/60\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 1.0000 - loss: 0.0082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30cc8d510>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=60, callbacks=[tb_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxhbsiGEooLE",
    "outputId": "93489d47-0976-4661-e44f-f7cc0d1585a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3101d8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3101d8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n",
      "\n",
      "Predicted :  normal-screen\n",
      "Actual :  normal-screen\n",
      "\n",
      "Predicted :  pause-play\n",
      "Actual :  pause-play\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  backward\n",
      "Actual :  pause-play\n",
      "\n",
      "Predicted :  backward\n",
      "Actual :  backward\n",
      "\n",
      "Predicted :  normal-screen\n",
      "Actual :  full-screen\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "for i in range(8):\n",
    "  print('\\nPredicted : ',actions[np.argmax(res[i])])\n",
    "  print('Actual : ',actions[np.argmax(y_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UOU74LqphDx",
    "outputId": "39796cda-558d-4345-c058-f2a5aaf257b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
