{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # # Draw face connections\n",
    "    # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "    #                          mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "    #                          mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "    #                          )\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    # face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('Point_Dataset_5') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['forward', 'backward', 'pause-play','full-screen','normal-screen'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(30,258)))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('forward'): 0,\n",
       " np.str_('backward'): 1,\n",
       " np.str_('pause-play'): 2,\n",
       " np.str_('full-screen'): 3,\n",
       " np.str_('normal-screen'): 4}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 0\n",
      "forward 1\n",
      "forward 2\n",
      "forward 3\n",
      "forward 4\n",
      "forward 5\n",
      "forward 6\n",
      "forward 7\n",
      "forward 8\n",
      "forward 9\n",
      "forward 10\n",
      "forward 11\n",
      "forward 12\n",
      "forward 13\n",
      "forward 14\n",
      "forward 15\n",
      "forward 16\n",
      "forward 17\n",
      "forward 18\n",
      "forward 19\n",
      "forward 20\n",
      "forward 21\n",
      "forward 22\n",
      "forward 23\n",
      "forward 24\n",
      "forward 25\n",
      "forward 26\n",
      "forward 27\n",
      "forward 28\n",
      "forward 29\n",
      "backward 0\n",
      "backward 1\n",
      "backward 2\n",
      "backward 3\n",
      "backward 4\n",
      "backward 5\n",
      "backward 6\n",
      "backward 7\n",
      "backward 8\n",
      "backward 9\n",
      "backward 10\n",
      "backward 11\n",
      "backward 12\n",
      "backward 13\n",
      "backward 14\n",
      "backward 15\n",
      "backward 16\n",
      "backward 17\n",
      "backward 18\n",
      "backward 19\n",
      "backward 20\n",
      "backward 21\n",
      "backward 22\n",
      "backward 23\n",
      "backward 24\n",
      "backward 25\n",
      "backward 26\n",
      "backward 27\n",
      "backward 28\n",
      "backward 29\n",
      "pause-play 0\n",
      "pause-play 1\n",
      "pause-play 2\n",
      "pause-play 3\n",
      "pause-play 4\n",
      "pause-play 5\n",
      "pause-play 6\n",
      "pause-play 7\n",
      "pause-play 8\n",
      "pause-play 9\n",
      "pause-play 10\n",
      "pause-play 11\n",
      "pause-play 12\n",
      "pause-play 13\n",
      "pause-play 14\n",
      "pause-play 15\n",
      "pause-play 16\n",
      "pause-play 17\n",
      "pause-play 18\n",
      "pause-play 19\n",
      "pause-play 20\n",
      "pause-play 21\n",
      "pause-play 22\n",
      "pause-play 23\n",
      "pause-play 24\n",
      "pause-play 25\n",
      "pause-play 26\n",
      "pause-play 27\n",
      "pause-play 28\n",
      "pause-play 29\n",
      "full-screen 0\n",
      "full-screen 1\n",
      "full-screen 2\n",
      "full-screen 3\n",
      "full-screen 4\n",
      "full-screen 5\n",
      "full-screen 6\n",
      "full-screen 7\n",
      "full-screen 8\n",
      "full-screen 9\n",
      "full-screen 10\n",
      "full-screen 11\n",
      "full-screen 12\n",
      "full-screen 13\n",
      "full-screen 14\n",
      "full-screen 15\n",
      "full-screen 16\n",
      "full-screen 17\n",
      "full-screen 18\n",
      "full-screen 19\n",
      "full-screen 20\n",
      "full-screen 21\n",
      "full-screen 22\n",
      "full-screen 23\n",
      "full-screen 24\n",
      "full-screen 25\n",
      "full-screen 26\n",
      "full-screen 27\n",
      "full-screen 28\n",
      "full-screen 29\n",
      "normal-screen 0\n",
      "normal-screen 1\n",
      "normal-screen 2\n",
      "normal-screen 3\n",
      "normal-screen 4\n",
      "normal-screen 5\n",
      "normal-screen 6\n",
      "normal-screen 7\n",
      "normal-screen 8\n",
      "normal-screen 9\n",
      "normal-screen 10\n",
      "normal-screen 11\n",
      "normal-screen 12\n",
      "normal-screen 13\n",
      "normal-screen 14\n",
      "normal-screen 15\n",
      "normal-screen 16\n",
      "normal-screen 17\n",
      "normal-screen 18\n",
      "normal-screen 19\n",
      "normal-screen 20\n",
      "normal-screen 21\n",
      "normal-screen 22\n",
      "normal-screen 23\n",
      "normal-screen 24\n",
      "normal-screen 25\n",
      "normal-screen 26\n",
      "normal-screen 27\n",
      "normal-screen 28\n",
      "normal-screen 29\n"
     ]
    }
   ],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        print(action,sequence)\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
      "\n",
      "Predicted :  pause-play\n",
      "Actual :  pause-play\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  full-screen\n",
      "Actual :  full-screen\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  backward\n",
      "Actual :  backward\n",
      "\n",
      "Predicted :  pause-play\n",
      "Actual :  pause-play\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n",
      "\n",
      "Predicted :  forward\n",
      "Actual :  forward\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "for i in range(8):\n",
    "  print('\\nPredicted : ',actions[np.argmax(res[i])])\n",
    "  print('Actual : ',actions[np.argmax(y_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[120,   0],\n",
       "        [  0,  30]],\n",
       "\n",
       "       [[119,   1],\n",
       "        [  0,  30]],\n",
       "\n",
       "       [[120,   0],\n",
       "        [  1,  29]],\n",
       "\n",
       "       [[120,   0],\n",
       "        [  1,  29]],\n",
       "\n",
       "       [[119,   1],\n",
       "        [  0,  30]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp=X\n",
    "out=y\n",
    "\n",
    "yhat = model.predict(inp)\n",
    "ytrue = np.argmax(out, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynput.keyboard import Key, Controller\n",
    "kb=Controller()\n",
    "\n",
    "commands={\n",
    "    'forward':Key.right,\n",
    "    'backward':Key.left,\n",
    "    'full-screen':'f',\n",
    "    'normal-screen':Key.esc,\n",
    "    'pause-play':Key.space\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.press('a')\n",
    "kb.release('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "0.99988174 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.9994098 pause-play\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "1.0 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "0.999355 forward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.99994636 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "0.9999889 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.99999297 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "0.9989749 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.9999901 normal-screen\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.9999993 full-screen\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.99993634 backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "0.9999976 backward\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "threshold = 0.97\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        # print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "\n",
    "        temp_seq=sequence\n",
    "        \n",
    "        if len(temp_seq) == 30:\n",
    "            res = model.predict(np.expand_dims(temp_seq, axis=0))[0]\n",
    "            result=actions[np.argmax(res)]\n",
    "            if np.max(res) > threshold:\n",
    "                print(np.max(res),result)\n",
    "                kb.press(commands[result])\n",
    "                kb.release(commands[result])\n",
    "            sequence=[]\n",
    "            \n",
    "            \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)  # Small delay to ensure windows close properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
